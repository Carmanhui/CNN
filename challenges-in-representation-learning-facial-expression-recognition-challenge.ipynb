{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 快速数据可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# size of the image: 48*48 pixels\n",
    "pic_size = 48\n",
    "# input path for the images\n",
    "base_path = \"../input/images/images/\"\n",
    "plt.figure(0, figsize=(12,20))\n",
    "cpt = 0\n",
    "for expression in os.listdir(base_path + \"train/\"):\n",
    "    for i in range(1,6):\n",
    "        cpt = cpt + 1\n",
    "        plt.subplot(7,5,cpt)\n",
    "        img = load_img(base_path + \"train/\" + expression + \"/\" +os.listdir(base_path + \"train/\" + expression)[i], target_size=(pic_size, pic_size))\n",
    "        plt.imshow(img, cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练图像的样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for expression in os.listdir(base_path + \"train\"):\n",
    "    print(str(len(os.listdir(base_path + \"train/\" + expression))) + \" \" + expression + \" images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置数据生成器ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# number of images to feed into the NN for every batch\n",
    "batch_size = 128\n",
    "datagen_train = ImageDataGenerator()\n",
    "datagen_validation = ImageDataGenerator()\n",
    "\n",
    "train_generator = datagen_train.flow_from_directory(base_path + \"train\",\n",
    "                                                    target_size=(pic_size,pic_size),\n",
    "                                                    color_mode=\"grayscale\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True)\n",
    "validation_generator = datagen_validation.flow_from_directory(base_path + \"validation\",\n",
    "                                                              target_size=(pic_size,pic_size),\n",
    "                                                              color_mode=\"grayscale\",\n",
    "                                                              batch_size=batch_size,\n",
    "                                                              class_mode='categorical',\n",
    "                                                              shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置我们的卷积神经网络（CNN）\n",
    "## 4个卷积层\n",
    "## 2个全连接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "# number of possible label values\n",
    "nb_classes = 7\n",
    "# Initialising the CNN\n",
    "model = Sequential()\n",
    "# 1 - Convolution\n",
    "model.add(Conv2D(64,(3,3), padding='same', input_shape=(48, 48,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "# 2nd Convolution layer\n",
    "model.add(Conv2D(128,(5,5), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "# 3rd Convolution layer\n",
    "model.add(Conv2D(512,(3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "# 4th Convolution layer\n",
    "model.add(Conv2D(512,(3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "# Flattening\n",
    "model.add(Flatten())\n",
    "# Fully connected layer 1st layer\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "# Fully connected layer 2nd layer\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "opt = Adam(lr=0.0001)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=train_generator.n//train_generator.batch_size,\n",
    "                              epochs=epochs,\n",
    "                              validation_data = validation_generator,\n",
    "                              validation_steps = validation_generator.n//validation_generator.batch_size,\n",
    "                              callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将CNN的结构保存到文件中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分析结果\n",
    "## 我们在训练阶段的每一步都获得了输出。所有这些输出都保存在“history”变量中。我们可以用它来绘制训练和验证数据集的损失和准确性的演变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.suptitle('Optimizer : Adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.plot(history.history['acc'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_acc'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 绘制混淆矩阵，以便了解我们的深度学习模型如何对图像进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(generator=validation_generator)\n",
    "y_pred = [np.argmax(probas) for probas in predictions]\n",
    "y_test = validation_generator.classes\n",
    "class_names = validation_generator.class_indices.keys()\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.tight_layout()\n",
    " \n",
    "# compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "# plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, title='Normalized confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实时预测\n",
    "## 首先让我们创建一个类，它将为我们提供先前训练模型的预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import numpy as np\n",
    "class FacialExpressionModel(object):\n",
    "    EMOTIONS_LIST = [\"Angry\", \"Disgust\",\"Fear\", \"Happy\",\"Neutral\", \"Sad\",\"Surprise\"]\n",
    "    def __init__(self, model_json_file, model_weights_file):\n",
    "        # load model from JSON file\n",
    "        with open(model_json_file, \"r\") as json_file:\n",
    "            loaded_model_json = json_file.read()\n",
    "            self.loaded_model = model_from_json(loaded_model_json)\n",
    "        # load weights into the new model\n",
    "        self.loaded_model.load_weights(model_weights_file)\n",
    "        self.loaded_model._make_predict_function()\n",
    "        \n",
    "    def predict_emotion(self, img):\n",
    "        self.preds = self.loaded_model.predict(img)\n",
    "        return FacialExpressionModel.EMOTIONS_LIST[np.argmax(self.preds)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现一个camera类\n",
    "### 从我们的网络摄像头获取图像流\n",
    "### 使用OpenCV检测面并添加边界框\n",
    "### 将面转换为灰度，rescale它们并将它们发送到我们预先训练的神经网络\n",
    "### 从我们的神经网络获取预测并将标签添加到网络摄像头图像\n",
    "### 返回最终的图像流"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from model import FacialExpressionModel\n",
    "import numpy as np\n",
    "facec = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "model = FacialExpressionModel(\"model.json\", \"model_weights.h5\")\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "class VideoCamera(object):\n",
    "    def __init__(self):\n",
    "        self.video = cv2.VideoCapture(0)\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.video.release()\n",
    "        \n",
    "    # returns camera frames along with bounding boxes and predictions\n",
    "    def get_frame(self):\n",
    "        _, fr = self.video.read()\n",
    "        gray_fr = cv2.cvtColor(fr, cv2.COLOR_BGR2GRAY)\n",
    "        faces = facec.detectMultiScale(gray_fr, 1.3, 5)\n",
    "        for (x, y, w, h) in faces:\n",
    "            fc = gray_fr[y:y+h, x:x+w]\n",
    "            roi = cv2.resize(fc, (48, 48))\n",
    "            pred = model.predict_emotion(roi[np.newaxis, :, :, np.newaxis])\n",
    "            cv2.putText(fr, pred, (x, y), font, 1, (255, 255, 0), 2)\n",
    "            cv2.rectangle(fr,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            \n",
    "        _, jpeg = cv2.imencode('.jpg', fr)\n",
    "        return jpeg.tobytes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最后，我们的主脚本将创建一个Flask应用程序，将我们的图像预测呈现到网页中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, Response\n",
    "from camera import VideoCamera\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "def gen(camera):\n",
    "    while True:\n",
    "        frame = camera.get_frame()\n",
    "        yield (b'--frame\\r\\n'\n",
    "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n\\r\\n')\n",
    "        \n",
    "@app.route('/video_feed')\n",
    "def video_feed():\n",
    "    return Response(gen(VideoCamera()),\n",
    "                    mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
